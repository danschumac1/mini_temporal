LOG INTO HUGGING FACE
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: read).
Your token has been saved to /home/dan/.cache/huggingface/token
Login successful
load model
`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.
Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use
`config.hidden_activation` if you want to override this behaviour.
See https://github.com/huggingface/transformers/pull/29402 for more details.
Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.38s/it]
tokenizer
load data

Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.33it/s]


Map: 100%|██████████| 60000/60000 [00:05<00:00, 10591.40 examples/s]
Traceback (most recent call last):
  File "/home/dan/mini_temporal/training/fine_tune_gemma_MIXED_nit.py", line 295, in <module>
    main()
  File "/home/dan/mini_temporal/training/fine_tune_gemma_MIXED_nit.py", line 216, in main
    train_data = other_preprocessing(train, tokenizer, args.model_context)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dan/mini_temporal/training/fine_tune_gemma_MIXED_nit.py", line 119, in other_preprocessing
    generated_text = tokenizer.decode(dataset[0][0], skip_special_tokens=False)
                                      ~~~~~~~~~~^^^
KeyError: 0