LOG INTO HUGGING FACE
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: read).
Your token has been saved to /home/dan/.cache/huggingface/token
Login successful
load model


Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:04,  2.00s/it]
tokenizer

Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.55s/it]
Data loaded
<bos><start_of_turn>user
Who did not ordain women until 1994?<end_of_turn>
<start_of_turn>model
The answer is: The Church of England.<end_of_turn>
<eos>
<class 'str'>



Map:  98%|█████████▊| 59000/60000 [00:06<00:00, 8290.81 examples/s]
<bos><start_of_turn>user
How many northern counties remained part of Britain until 1922?<end_of_turn>
<start_of_turn>model
The answer is: six.<end_of_turn>
<eos>
<class 'str'>
Data preprocessed
Map: 100%|██████████| 60000/60000 [00:06<00:00, 9324.63 examples/s]
Map: 100%|██████████| 7500/7500 [00:00<00:00, 9993.60 examples/s]
/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
Trainable: 100007936 | total: 8637688832 | Percentage: 1.1578%
Model prepared for training
Trainer set up
/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
  0%|          | 0/1872 [00:00<?, ?it/s]/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.
  warnings.warn(
























  1%|▏         | 25/1872 [1:58:20<147:53:27, 288.26s/it]
{'loss': 5.8355, 'grad_norm': 23.321184158325195, 'learning_rate': 1.9743452699091396e-05, 'epoch': 0.05}





















































































































































































































































































































































































































































































100%|██████████| 469/469 [1:36:50<00:00, 11.61s/it]







