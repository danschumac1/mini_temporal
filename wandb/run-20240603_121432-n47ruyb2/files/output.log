LOG INTO HUGGING FACE
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: read).
Your token has been saved to /home/dan/.cache/huggingface/token
Login successful
load model
`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.
Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use
`config.hidden_activation` if you want to override this behaviour.
See https://github.com/huggingface/transformers/pull/29402 for more details.
Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:01<00:01,  1.36s/it]
tokenizer
load data

Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.35it/s]
<bos>Who did not ordain women until 1994? The answer is: The Church of England<eos>
<class 'str'>

Map:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 55000/60000 [00:03<00:00, 14447.02 examples/s]
<bos>How many northern counties remained part of Britain until 1922? The answer is: six<eos>
<class 'str'>
Data preprocessed
lora
Trainable: 78446592 | total: 2584619008 | Percentage: 3.0351%
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60000/60000 [00:03<00:00, 15898.87 examples/s]
Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7500/7500 [00:00<00:00, 18726.49 examples/s]
/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(
Trainer set up
/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
  0%|          | 0/468 [00:00<?, ?it/s]/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.
  warnings.warn(















  5%|‚ñå         | 24/468 [07:42<2:23:08, 19.34s/it]
  5%|‚ñå         | 25/468 [08:00<2:21:20, 19.14s/it]



































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 467/469 [06:29<00:01,  1.13it/s]
























 10%|‚ñà         | 49/468 [22:13<2:11:56, 18.89s/it]
 11%|‚ñà         | 50/468 [22:32<2:12:05, 18.96s/it]


































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 467/469 [06:28<00:01,  1.13it/s]


























 16%|‚ñà‚ñå        | 75/468 [37:08<2:08:04, 19.55s/it]
{'loss': 2.5031, 'grad_norm': 1.4563595056533813, 'learning_rate': 1.683083511777302e-05, 'epoch': 0.16}


































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 468/469 [06:29<00:00,  1.14it/s]

























 21%|‚ñà‚ñà        | 99/468 [51:25<1:59:03, 19.36s/it]
 21%|‚ñà‚ñà‚ñè       | 100/468 [51:45<1:59:52, 19.55s/it]



































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 467/469 [06:29<00:01,  1.12it/s]
























 26%|‚ñà‚ñà‚ñã       | 124/468 [1:06:00<1:54:01, 19.89s/it]
 27%|‚ñà‚ñà‚ñã       | 125/468 [1:06:20<1:53:04, 19.78s/it]




































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 467/469 [06:30<00:01,  1.12it/s]
























 32%|‚ñà‚ñà‚ñà‚ñè      | 149/468 [1:20:40<1:42:50, 19.34s/it]
 32%|‚ñà‚ñà‚ñà‚ñè      | 150/468 [1:20:59<1:42:01, 19.25s/it]



































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 468/469 [06:30<00:00,  1.13it/s]

























 37%|‚ñà‚ñà‚ñà‚ñã      | 174/468 [1:35:21<1:33:52, 19.16s/it]
 37%|‚ñà‚ñà‚ñà‚ñã      | 175/468 [1:35:40<1:33:59, 19.25s/it]



































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 467/469 [06:29<00:01,  1.13it/s]

























 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 199/468 [1:49:54<1:28:00, 19.63s/it]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 200/468 [1:50:13<1:26:02, 19.26s/it]



































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 467/469 [06:29<00:01,  1.13it/s]


























 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 225/468 [2:04:47<1:20:02, 19.76s/it]
{'loss': 2.2775, 'grad_norm': 1.379813313484192, 'learning_rate': 1.0406852248394007e-05, 'epoch': 0.48}


































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 467/469 [06:27<00:01,  1.13it/s]
























 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 249/468 [2:18:57<1:11:15, 19.52s/it]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 250/468 [2:19:17<1:11:25, 19.66s/it]



































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 467/469 [06:28<00:01,  1.13it/s]
























 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 274/468 [2:33:33<1:01:58, 19.17s/it]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 275/468 [2:33:52<1:01:53, 19.24s/it]


































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 467/469 [06:28<00:01,  1.13it/s]


























 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 300/468 [2:48:24<53:31, 19.12s/it]
{'loss': 2.2358, 'grad_norm': 1.2936489582061768, 'learning_rate': 7.194860813704497e-06, 'epoch': 0.64}


































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [06:29<00:00,  1.23it/s]


























 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 325/468 [3:02:54<46:08, 19.36s/it]
{'loss': 2.2314, 'grad_norm': 1.2616668939590454, 'learning_rate': 6.124197002141328e-06, 'epoch': 0.69}



































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 468/469 [06:31<00:00,  1.13it/s]

























 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 349/468 [3:17:09<37:58, 19.15s/it]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 350/468 [3:17:28<37:43, 19.19s/it]




































































































































































































 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 466/469 [06:29<00:02,  1.16it/s]
























 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 374/468 [3:31:49<30:24, 19.41s/it]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 375/468 [3:32:09<30:23, 19.61s/it]



































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 468/469 [06:31<00:00,  1.13it/s]


























 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 400/468 [3:46:51<22:04, 19.48s/it]
{'loss': 2.217, 'grad_norm': 1.3643293380737305, 'learning_rate': 2.9122055674518203e-06, 'epoch': 0.85}


































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 468/469 [06:29<00:00,  1.14it/s]

























 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 424/468 [4:01:02<14:05, 19.21s/it]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 425/468 [4:01:22<13:58, 19.49s/it]



































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 468/469 [06:30<00:00,  1.14it/s]

























 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 450/468 [4:16:00<05:51, 19.52s/it]
  0%|          | 0/469 [00:00<?, ?it/s]



































































































































































































100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 468/469 [06:30<00:00,  1.14it/s]


















100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 467/468 [4:28:01<00:19, 19.39s/it]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 468/468 [4:28:21<00:00, 34.40s/it]
/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Model and tokenizer saved at ./training/models/AQA/gemma-2b/no_context