LOG INTO HUGGING FACE
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: read).
Your token has been saved to /home/dan/.cache/huggingface/token
Login successful
load model
`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.
Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use
`config.hidden_activation` if you want to override this behaviour.
See https://github.com/huggingface/transformers/pull/29402 for more details.
Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.35s/it]
tokenizer
load data
Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]

Map:  67%|██████▋   | 40000/60000 [00:02<00:00, 20638.07 examples/s]
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 60000
})
Dataset({
    features: ['input_ids', 'attention_mask'],
    num_rows: 7500
})
Data preprocessed
Map: 100%|██████████| 60000/60000 [00:02<00:00, 20549.49 examples/s]
Map: 100%|██████████| 7500/7500 [00:00<00:00, 17124.72 examples/s]
Trainable: 78446592 | total: 2584619008 | Percentage: 3.0351%
Model prepared for training
Trainer set up
/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead
  warnings.warn(
/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
  0%|          | 0/468 [00:00<?, ?it/s]/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.
  warnings.warn(












  5%|▌         | 24/468 [08:14<2:29:31, 20.21s/it]

























 10%|█         | 49/468 [16:47<2:23:05, 20.49s/it]

























 16%|█▌        | 74/468 [25:24<2:16:23, 20.77s/it]

























 21%|██        | 99/468 [33:57<2:05:57, 20.48s/it]

























 26%|██▋       | 124/468 [42:27<1:57:43, 20.53s/it]

























 32%|███▏      | 149/468 [51:02<1:49:49, 20.66s/it]

























 37%|███▋      | 174/468 [59:30<1:40:35, 20.53s/it]

























 43%|████▎     | 199/468 [1:08:07<1:33:11, 20.78s/it]

























 48%|████▊     | 224/468 [1:16:40<1:22:37, 20.32s/it]

























 53%|█████▎    | 249/468 [1:25:15<1:14:39, 20.46s/it]

























 59%|█████▊    | 274/468 [1:33:52<1:06:43, 20.64s/it]

























 64%|██████▍   | 299/468 [1:42:20<57:32, 20.43s/it]

























 69%|██████▉   | 324/468 [1:50:58<49:46, 20.74s/it]

























 75%|███████▍  | 349/468 [1:59:34<41:27, 20.91s/it]

























 80%|███████▉  | 374/468 [2:08:10<32:24, 20.68s/it]

























 85%|████████▌ | 399/468 [2:16:47<23:27, 20.39s/it]

























 91%|█████████ | 424/468 [2:25:18<14:57, 20.39s/it]

























 96%|█████████▌| 449/468 [2:33:49<06:31, 20.63s/it]


















100%|██████████| 468/468 [2:40:20<00:00, 20.56s/it]
/home/dan/miniconda3/envs/danEnv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'train_runtime': 9621.9469, 'train_samples_per_second': 6.236, 'train_steps_per_second': 0.049, 'train_loss': 1.4980931404309394, 'epoch': 1.0}
Model and tokenizer saved at ./training/models/AQA/gemma-2b/random_context